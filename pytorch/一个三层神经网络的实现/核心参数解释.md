1. **W (Weights)**：权重
    
    - 表示连接不同层之间的边的强度。权重决定了输入信号对输出信号的影响程度。
    - 在代码中，`network['W1']` 是第一层（输入层到隐藏层）的权重矩阵。
    - 例如，`network['W1']` 的形状为 (2,3)(2,3)，表示输入层有2个神经元，第一层有3个神经元。它的值是一个numpy数组。
2. **b (Bias)**：偏置
    
    - 偏置是加在每一层神经元上的常数值，用来调整输出。
    - 通过调整偏置，模型可以更好地拟合训练数据。
    - 在代码中，`network['b1']` 是第一层的偏置向量，形状为 (3,)(3,)，表示第一层有3个神经元的偏置。
    - a1 = np.dot(x, W1) + b1
1. **a (Activation)**：激活值
    
    - 激活值是从输入信号（经过线性组合后，通常就是加权和加上偏置）得到的。它是每一层神经元的输出值，在传递到下一层之前需要经过激活函数的转化。
    - 在代码中，`a1`, `a2` 和 `a3` 分别是第一层、第二层和第三层的激活值。
4. **z (Z-Values)**：层输出（经过激活函数后的值）
    
    - `z` 是针对每一层应用激活函数后的结果。它用于作为下一层的输入。
    - 在代码中，`z1`, `z2` 是第一层和第二层的输出值，经过激活： z1 = sigmoid(a1)
5. **y (Output)**：最终输出
    
    - 最终神经网络的输出值，
    - 在代码中，`y` 是第三层的输出，经过恒等函数（意味着直接输出激活值）。


代码中：
- `network['W1']` 得到第一个权重矩阵。
- `network['b2']` 得到第二层的偏置向量。